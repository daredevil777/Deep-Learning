{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, LeakyReLU, DepthwiseConv2D, Flatten\nfrom keras.layers.pooling import GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm, tqdm_notebook\n\nimport numpy as np\nimport pandas as pd\nimport cv2 as cv\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/aerial-cactus-identification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = Sequential()\n        \n    model.add(Conv2D(3, kernel_size = 3, activation = 'relu', input_shape = (32, 32, 3)))\n    \n    model.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\n    model.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 32, kernel_size = 1, activation = 'relu'))\n    model.add(Conv2D(filters = 64, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 2, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 128, kernel_size = 1, activation = 'relu'))\n    model.add(Conv2D(filters = 256, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 256, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 2, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 1024, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 1024, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 2048, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n     #model.add(GlobalAveragePooling2D())\n    model.add(Flatten())\n    \n    model.add(Dense(470, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(256, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(128, activation = 'tanh'))\n\n    model.add(Dense(1, activation = 'sigmoid'))\n\n    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error', metrics = ['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = 'weights-aerial-cactus.h5'\n\ncallbacks = [\n        ModelCheckpoint(file_path, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max'),\n        ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, mode = 'min', min_lr = 0.00001),\n        EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 15, verbose = 1, restore_best_weights = True)\n        ]\n\ntraining_path = '../input/aerial-cactus-identification/train/train/'\ntest_path = '../input/aerial-cactus-identification/test/test/'\nimages_train = []\nlabels_train = []\n\nimages = train_data['id'].values\nfor image_id in tqdm_notebook(images):\n    \n    image = np.array(cv.imread(training_path + image_id))\n    label = train_data[train_data['id'] == image_id]['has_cactus'].values[0]\n    #print(label)\n    images_train.append(image)\n    labels_train.append(label)\n    \n    images_train.append(np.flip(image))\n    labels_train.append(label)\n    \n    images_train.append(np.flipud(image))\n    labels_train.append(label)\n    \n    images_train.append(np.fliplr(image))\n    labels_train.append(label)\n    \n    \nimages_train = np.asarray(images_train)\nimages_train = images_train.astype('float32')\nimages_train /= 255.\n\nlabels_train = np.asarray(labels_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images_names = []\n\nfor filename in os.listdir(test_path):\n    test_images_names.append(filename)\n    \ntest_images_names.sort()\n\nimages_test = []\n\nfor image_id in tqdm_notebook(test_images_names):\n    images_test.append(np.array(cv.imread(test_path + image_id)))\n    \nimages_test = np.asarray(images_test)\nimages_test = images_test.astype('float32')\nimages_test /= 255\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(images_train, labels_train, test_size = 0.2, stratify = labels_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.optimizer.lr=0.001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, \n            y_train, \n            batch_size = 128, \n            epochs = 10, \n            validation_data = (x_test, y_test),\n            verbose = 1,\n            callbacks = callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(file_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(images_test, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_training_curves(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1, len(acc) + 1)\n    \n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n    plt.title('Losses')\n    plt.legend()\n    plt.figure()\n    \n    plt.plot(epochs, acc, 'r', label='Training acc')\n    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n    plt.title('Accuracies')\n    plt.legend()\n    plt.figure()\n    \n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training_curves(history)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}